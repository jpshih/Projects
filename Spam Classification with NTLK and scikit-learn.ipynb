{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Spam Classification using NLTK and scikit-learn\n",
    "\n",
    "\n",
    "1. Load and clean Enron spam e-mails text\n",
    "2. Generate stopwords list\n",
    "3. Set up pipelines for a Multinomial Naive Bayes model and a LinearSVM model\n",
    "4. Use k-fold cross validation to compare classification model results\n",
    "\n",
    "\n",
    "Multinomial Naive Bayes counts occurences and is suitable for datasets with discrete features while SVM models are good for linearly separable datasets with many features (such as text), making the two models a good choice for spam classification problems.\n",
    "\n",
    "A k-fold cross validation method was chosen for facilitating the training/test set splits. In k-fold cross validation, the data is partitioned into k subsets. Each set is held for validation while the other k-1 sets are used for training. Average error across all trials is then calculated.\n",
    "\n",
    "Each model pipeline was tuned experimenting with different n-gram counts and tf-idf weighting. The best results are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer       \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Subject                       forwarded by vin...\n",
       "1    Subject    direct marketing will increase sale...\n",
       "2    Subject   http    www  virtu  ally  anywhere  ...\n",
       "3    Subject  gorgeous  custom websites   399 compl...\n",
       "4    Subject   content  type  text  plain  charset ...\n",
       "5    Subject  enron day  to be declared in spearman...\n",
       "6    Subject  help millions   pledge today   thank ...\n",
       "7    Subject  henwood  s rationalizing midwest powe...\n",
       "8    Subject  we are one  enron  com    final notic...\n",
       "9    Subject           guaranteed  50  000 fast    ...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset with e-mail text and a spam/not spam binary indicator \n",
    "emails = pd.read_csv(\"C:/Users/Julie/Desktop/BAPM/Online Learning Materials/Python/emails.csv\",usecols=[0,1])\n",
    "\n",
    "# remove punctuation\n",
    "emails['cleaned'] = emails['text'].apply(lambda x:''.join([i for i in x \n",
    "                                                  if i not in string.punctuation]))\n",
    "emails['cleaned'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'mightn',\n",
       " u'mustn',\n",
       " u'needn',\n",
       " u'shan',\n",
       " u'shouldn',\n",
       " u'wasn',\n",
       " u'weren',\n",
       " u'won',\n",
       " u'wouldn',\n",
       " 'subject']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopword list to use\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.append('subject') # add 'subject' to stopwords list\n",
    "\n",
    "stopwords_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents classified: 5726\n",
      "Score: 0.95857454499\n",
      "Confusion matrix:\n",
      "[[4354    4]\n",
      " [  74 1294]]\n"
     ]
    }
   ],
   "source": [
    "# set up pipeline for Naive Bayes Classifier\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2), #tokenizes words from unigram up to bigrams\n",
    "                                         lowercase = True, #convert text to lowercase\n",
    "                                         stop_words = stopwords_list)), #remove stopwords\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "#10 fold cross validation\n",
    "k_fold = KFold(n=len(emails), n_folds=10)\n",
    "scores = []\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = emails.iloc[train_indices]['cleaned'].values\n",
    "    train_y = emails.iloc[train_indices]['spam'].values\n",
    "\n",
    "    test_text = emails.iloc[test_indices]['cleaned'].values\n",
    "    test_y = emails.iloc[test_indices]['spam'].values\n",
    "\n",
    "    #fit the model\n",
    "    pipeline1.fit(train_text, train_y)\n",
    "    predicted = pipeline1.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predicted)\n",
    "    score = f1_score(test_y, predicted)\n",
    "    scores.append(score)\n",
    "\n",
    "print 'Total documents classified:', len(emails)\n",
    "print 'Score:', sum(scores)/len(scores)\n",
    "print 'Confusion matrix:'\n",
    "print confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents classified: 5726\n",
      "Score: 0.971238559526\n",
      "Confusion matrix:\n",
      "[[4346   12]\n",
      " [  45 1323]]\n"
     ]
    }
   ],
   "source": [
    "#set up LinearSVC pipeline\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer( lowercase = True, #convert text to lowercase\n",
    "                                          stop_words = stopwords_list)), #remove stopwords\n",
    "    ('tfidf_transformer',  TfidfTransformer()), #weighs terms by importance to help with feature selection\n",
    "    ('classifier', LinearSVC())\n",
    "])\n",
    "\n",
    "k_fold = KFold(n=len(emails), n_folds=10)\n",
    "scores = []\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = emails.iloc[train_indices]['cleaned'].values\n",
    "    train_y = emails.iloc[train_indices]['spam'].values\n",
    "\n",
    "    test_text = emails.iloc[test_indices]['cleaned'].values\n",
    "    test_y = emails.iloc[test_indices]['spam'].values\n",
    "\n",
    "    pipeline2.fit(train_text, train_y)\n",
    "    predicted = pipeline2.predict(test_text)\n",
    "\n",
    "    confusion += confusion_matrix(test_y, predicted)\n",
    "    score = f1_score(test_y, predicted)\n",
    "    scores.append(score)\n",
    "\n",
    "print 'Total documents classified:', len(emails)\n",
    "print 'Score:', sum(scores)/len(scores)\n",
    "print 'Confusion matrix:'\n",
    "print confusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models return fairly good results, with the LinearSVM model classifying 97.1% of e-mails correctly. In spam classification, it is important to minimize **false positives** so that legitimate e-mails are not classified as spam. With respect to false positives, the Multinomial Naive Bayes model demonstrates better performance with only 4 false positives and a score of 95.8% e-mails classified correctly.\n",
    "\n",
    "\n",
    "\n",
    "References:  \n",
    "http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html  \n",
    "http://blog.manugarri.com/sentiment-analysis-in-spanish/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
